{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модуль Б. Разработка модели машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импортирование библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import zipfile\n",
    "\n",
    "#\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# \n",
    "import pandas as pd\n",
    "\n",
    "#\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "import os\n",
    "\n",
    "# \n",
    "from deepface import DeepFace\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "['face_detection.zip', 'face_recognition.zip']\n"
     ]
    }
   ],
   "source": [
    "# назначаем основные пути\n",
    "module_dir = os.getcwd()\n",
    "main_dir = module_dir[:-8]\n",
    "data_dir = os.path.join(main_dir, r'Module1\\Data')\n",
    "# логирование\n",
    "print(os.path.exists(main_dir))\n",
    "print(os.path.exists(data_dir))\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Helper\\MLBazyak\\chemp\\face_recognitionV2\\Module1\\Data\\face_detection.zip\n",
      "d:\\Helper\\MLBazyak\\chemp\\face_recognitionV2\\Module1\\Data\\face_recognition.zip\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# получаем пути к архивам\n",
    "face_det_zip = os.path.join(data_dir, os.listdir(data_dir)[0])\n",
    "face_rec_zip = os.path.join(data_dir, os.listdir(data_dir)[1])\n",
    "# логирование\n",
    "print(face_det_zip)\n",
    "print(face_rec_zip)\n",
    "print(os.path.exists(face_det_zip))\n",
    "print(os.path.exists(face_rec_zip))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем папку с данными\n",
    "module_data_path = os.path.join(module_dir, 'Data')\n",
    "os.makedirs(module_data_path, exist_ok=True)\n",
    "# и папки с данными для детекции и распознавания\n",
    "face_det = os.path.join(module_data_path, 'face_detection')\n",
    "face_rec = os.path.join(module_data_path, 'face_recognition')\n",
    "os.makedirs(face_det, exist_ok=True)\n",
    "os.makedirs(face_rec, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для продолжения работы, надо разархивировать данные с прошлого модуля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные успешно разархивированны\n"
     ]
    }
   ],
   "source": [
    "# датасет для детекции\n",
    "with zipfile.ZipFile(face_det_zip, 'r') as zip:\n",
    "    # выгружаем файлы из архива\n",
    "    zip.extractall(face_det)\n",
    "\n",
    "# датасет для распознавания\n",
    "with zipfile.ZipFile(face_rec_zip, 'r') as zip:\n",
    "    # выгружаем файлы из архива\n",
    "    zip.extractall(face_rec)\n",
    "\n",
    "print('Данные успешно разархивированны')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор алгоритма машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Алгоритм детекции:**\n",
    "\n",
    "В качестве алгоритма детекции, я буду использовать предобученную модель из семейства `YOLO` - `yolov8n` (nano-версия YOLOv8). Это самая маленькая модель из линейки, обеспечивает оптимальный баланс между точностью и скоростью. Это может быть важно, для решения задач реального времени (в нашем случае - детекция лиц).\n",
    "\n",
    "Также, модель достаточно легкая, что позволяет работать на устройствах с ограниченными вычислительными мощностями, и так как в моем распоряжении только CPU (процессор), подобная модель будет оптимальным выбором\n",
    "\n",
    "Архитектура моделей из семейства `YOLO` - разработана для решения задачи детекции, и обрабатывает изображение за 1 проход через нейронную сеть. Это делает подобные модели быстрее по сравнению с другими подходами, такими как `R-CNN` или `Faster R-CNN`.\n",
    "\n",
    "`YOLOv8` поставляется с предобученными весами, что позволяет использовать ее сразу, или дообучить модель на собственных данных, настроив ее на более точное решение задачи\n",
    "\n",
    "У `YOLOv8` простой и удобный API, который позволяет быстро начать работу с моделью, интегрируя ее в свой проект\n",
    "\n",
    "Хоть мы и берем веса `nano`, всегда есть возможность переключить на более тяжелые модели, например `medium` или `large`, так как `YOLO` легко масштабируется\n",
    "\n",
    "По итогу, я считаю что для моей задачи данная модель - наилучший вариант, поэтому для своего решения я буду использовать именно её"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Алгоритм распознования:**\n",
    "\n",
    "В качестве алгоритма распознавания, я буду использовать `косинусное сходство` `эмбеддингов`, извлеченных с помощью модели `Facenet512` из библиотеки `DeepFace`\n",
    "\n",
    "**Facenet512**\n",
    "\n",
    "Модель `Facenet512` - одна из самых популярных и точных моделей для задач распознавания лиц. Она основана на архитектуре глубоких нейронных сетей, и предобученна на больших наборах данных\n",
    "\n",
    "Модель преобразует фотографии в `512-мерные` эмбеддинге (векторные представления), которые эффективно кодируют уникальные черты лица\n",
    "\n",
    "`Facenet512` показывает отличные результаты на стандартных `бенчмарках`, что делает ее надежным выбором для задач распознавания\n",
    "\n",
    "Модель извлекает эмбеддинги за 1 проход через нейронную сеть, что делает процесс быстрым и эффективным\n",
    "\n",
    "Также, Facenet512 устойчива к различным вариациям изображений, что делает ее подходящей для работы в реальных условиях\n",
    "\n",
    "--------------------------------------------------------------------------\n",
    "\n",
    "**Косинусное сходство**\n",
    "\n",
    "`Косинусное сходство` - это метрика, которая измеряет угол между двумя векторами в многомерном пространстве. Она идеально подходит для сравнения эмбеддингов, так как :\n",
    "- не зависит от длины векторов\n",
    "- фокусируется на направлении векторов\n",
    "\n",
    "Метрика возвращает значение в диапазоне от `-1 до 1`, где 1 означает `полное совпадение`, а -1 - `полное различие`\n",
    "\n",
    "Метрика проста в вычислении и интерпретации, что делает ее удобной для `задач распознавания`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель детекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:01<00:00, 3.58MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель распознавания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "подготовка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Разделение фото на выборки..: 100%|██████████| 31/31 [01:14<00:00,  2.42s/image]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Разделение на выборки завершено\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# папки с фотографиями\n",
    "crop_source = './Data/face_recognition/Faces/Faces'\n",
    "train = './Data/face_recognition/train'\n",
    "test = './Data/face_recognition/test'\n",
    "\n",
    "# если папки с выборками нет - создаем их\n",
    "os.makedirs(train, exist_ok=True)\n",
    "os.makedirs(test, exist_ok=True)\n",
    "\n",
    "# словарь с именами людей и их фотографиями\n",
    "names_dict = {}\n",
    "counter = 0\n",
    "#\n",
    "for file_name in os.listdir(crop_source):\n",
    "    name = file_name.split('_')[0]\n",
    "    names_dict.setdefault(name, []).append(file_name)\n",
    "    counter +=1\n",
    "\n",
    "for name, data in tqdm(names_dict.items(), desc='Разделение фото на выборки..', unit='image'):\n",
    "    random.shuffle(data)\n",
    "    # процент от всех данных (80% - train, остальное - test)\n",
    "    split_value = int(len(data)*0.80)\n",
    "    # разделяем список на выборки\n",
    "    train_files, test_files = data[:split_value], data[split_value:]\n",
    "\n",
    "    # для каждого имени создаем папку\n",
    "    os.makedirs(os.path.join(train, name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test, name), exist_ok=True)\n",
    "\n",
    "    # копируем файлы в созданные папки\n",
    "    for file in train_files:\n",
    "        shutil.copy(os.path.join(crop_source, file), os.path.join(train, name, file))\n",
    "    for file in test_files:\n",
    "        shutil.copy(os.path.join(crop_source, file), os.path.join(test, name, file))\n",
    "\n",
    "print('Разделение на выборки завершено')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработка фотографий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пайплайн для обработки фотографий\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),   # изменение размера на 224х224\n",
    "    transforms.ToTensor(),          # приведение к тензору\n",
    "    transforms.Normalize([0.5],[0.5]) # нормализация (mean=0.5, std=0.5)\n",
    "])\n",
    "\n",
    "# загружаем папки с фотграфиями\n",
    "train_dataset = ImageFolder(root=train, transform=transform)\n",
    "test_dataset = ImageFolder(root=test, transform=transform)\n",
    "\n",
    "# создаем датасеты из папок\n",
    "train_loader = DataLoader()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
